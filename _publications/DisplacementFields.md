---
short: 'MultimodalDance'
title: 'Multimodal Dance Recognition'
collection: publications
permalink: /publications/MultimodalDance
thumbnail: /images/approach.png
date: 2020
venue: 'VISIGRAPP (5: VISAPP)'
authors: '<a href="/about.html">Monika Wysoczanska</a><sup>*</sup>, Tomasz Trzcinski <br> <small><i><sup></sup></i></small>
abstract: "Video content analysis is still an emerging technology, and the majority of work in this area extends from the
still image domain. Dance videos are especially difficult to analyse and recognise as the performed human actions are highly dynamic. In this work, we introduce a multimodal approach for dance video recognition. Our
proposed method combines visual and audio information, by fusing their representations, to improve classification accuracy. For the visual part, we focus on motion representation, as it is the key factor in distinguishing
dance styles. For audio representation, we put the emphasis on capturing long-term dependencies, such as
tempo, which is a crucial dance discriminator. Finally, we fuse two distinct modalities using a late fusion
approach. We compare our model with corresponding unimodal approaches, by giving exhaustive evaluation
on the Letâ€™s Dance dataset. Our method yields significantly better results than each single-modality approach.
Results presented in this work not only demonstrate the strength of integrating complementary sources of information in the recognition task, but also indicate the potential of applying multimodal approaches within
specific research areas."

code: "https://github.com/wysoczanska/Dance-Recognition"
pdf: "https://www.scitepress.org/Papers/2020/93260/93260.pdf"
---

